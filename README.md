# GPU-Optimization-Roadmap
This repository is part of a structured curriculum designed to master GPU optimization, Triton, Deep Learning, and LLMs. This section focuses on GPU fundamentals, CUDA programming, and PyTorch optimizations.

# Week 1: GPU Fundamentals & CUDA with Python

âœ… Learn about CUDA cores, memory hierarchy, warps, and threads<br>
âœ… Implement basic GPU computations using Numba and PyCUDA<br>
âœ… Profile GPU performance using NVIDIA Nsight SystemsğŸ› ï¸ Assignment: Implement a GPU-accelerated matrix multiplication using Numba and compare it with PyTorchâ€™s torch.matmul.

# Week 2: PyTorch & CUDA Optimizations

âœ… Understand PyTorch's computation graph, autograd, and JIT<br>
âœ… Learn memory-efficient tensor operations (in-place operations, pinned memory)<br>
âœ… Optimize PyTorch models with torch.compile and torch.jitğŸ› ï¸ Assignment: Optimize a PyTorch model using torch.compile and benchmark improvements.

# Week 3: Triton for High-Performance Kernels

âœ… Introduction to Triton: Why it outperforms CUDA for ML workloads<br>
âœ… Write custom Triton kernels for matrix multiplication<br>
âœ… Understand memory access patterns in TritonğŸ› ï¸ Assignment: Implement a Triton kernel for faster softmax and compare with PyTorch.

# ğŸ“‚ Repository Structure
```
ğŸ“‚ gpu-optimization-roadmap
 â”œâ”€â”€ ğŸ“ week1_cuda_python
 â”‚   â”œâ”€â”€ matrix_multiplication_numba.py
 â”‚   â”œâ”€â”€ profiling_with_nsight.md
 â”‚   â””â”€â”€ README.md
 â”œâ”€â”€ ğŸ“ week2_pytorch_optimizations
 â”‚   â”œâ”€â”€ torch_compile_benchmarks.ipynb
 â”‚   â”œâ”€â”€ memory_optimizations.md
 â”‚   â””â”€â”€ README.md
 â”œâ”€â”€ ğŸ“ week3_triton_kernels
 â”‚   â”œâ”€â”€ softmax_triton.py
 â”‚   â”œâ”€â”€ performance_comparisons.md
 â”‚   â””â”€â”€ README.md
 â”œâ”€â”€ README.md
```

# ğŸ“– Resources
ğŸ“Œ Numba CUDA Programming Guide - [Resource 1](https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html), [Resource 2](https://github.com/numba/nvidia-cuda-tutorial?tab=readme-ov-file), [Numba Docs](https://numba.readthedocs.io/en/stable/cuda/overview.html) <br>
ğŸ“Œ PyCUDA Documentation - [PyCUDA Docs](https://documen.tician.de/pycuda/) <br>
ğŸ“Œ PyTorch Profiler Guide - [PyTorch Docs](https://pytorch.org/tutorials/recipes/recipes/profiler_recipe.html) <br>
ğŸ“Œ Triton Tutorials - [Triton Docs](https://triton-lang.org/main/index.html), [Youtube](https://www.youtube.com/watch?v=86FAWCzIe_4&t=30156s) <br>

# ğŸ¤ Contributing
Feel free to contribute by adding optimized CUDA/Triton kernels, PyTorch tricks, or real-world case studies!
